{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare original and Compiled models\n",
    "\n",
    "## Step 1: First start by downloading them ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the stored variables (variables stored in Lab1)\n",
    "#  The variables represent a string format of the S3 location where the model is stored:\n",
    "#       Example: s3://sagemaker-us-east-1-<accountnumber>/ml_m4/model-ml_m4.tar.gz\n",
    "\n",
    "%store -r model_optimized\n",
    "%store -r model_original\n",
    "\n",
    "print('S3 Location for Optimized Model:', model_optimized)\n",
    "print('S3 Location for Original Model:', model_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the model objects to storage local to this notebook instance\n",
    "!aws s3 cp {model_optimized} ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {model_original} ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory and extract original model\n",
    "!mkdir original & tar -xzvf model.tar.gz -C original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory and extract compiled model\n",
    "!mkdir compiled & tar -xzvf model-ml_m4.tar.gz -C compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Local inference - original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upgrade TensorFlow on Notebook Instance:** We will upgrade to TF 2.0 to demonstrate how you can use saved_models from older (in this case, 1.18.0) versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda uninstall wrapt -y\n",
    "!pip install tensorflow==2.0.0\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "print(tf.__version__)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and serving signature\n",
    "\n",
    "Find the path to protobuf file (*pb) file for the original model & load it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = !find ./original/ -type f -name \"*.pb\"\n",
    "path = path[0][:-14]\n",
    "print('Notebook Instance Path to pb file:', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved model back into Python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the serving signature of the original [saved model](https://www.tensorflow.org/guide/saved_model)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir {path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(loaded.signatures.keys())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading signatures and printing dictionary results returned.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = loaded.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load example image: Load and resize an image stored on this notebook instance under the /data directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "print(image.shape)\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "i = tf.image.convert_image_dtype(image.reshape(-1,32,32,3),tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check single inference from image loaded above.  The JSON reponse will be the probabilities of the image belonging to one of the 10 classes along with the most likely class the picture belongs to. The classes can be referenced from the [CIFAR-10 website](https://www.cs.toronto.edu/~kriz/cifar.html). Since we didn't train the model for that long, we aren't expecting very accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "infer(i)['probabilities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean value using python [timeit](https://docs.python.org/3/library/timeit.html) module for measuring inference time on the original model.  We will use this value for comparison later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_original = %timeit -n25 -r25 -o infer(i)['probabilities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Local inference - compiled model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLR or Deep Learning Runtime is a part of Neo (https://github.com/neo-ai/neo-ai-dlr) is a compact, common runtime for deep learning models and decision tree models compiled by AWS SageMaker Neo, TVM, or Treelite. DLR uses the TVM runtime, Treelite runtime, NVIDIA TensorRTâ„¢, and can include other hardware-specific runtimes. DLR provides unified Python/C++ APIs for loading and running compiled models on various devices. DLR currently supports platforms from Intel, NVIDIA, and ARM, with support for Xilinx, Cadence, and Qualcomm coming soon.\n",
    "\n",
    "Install Deep Learning Runtime..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the compiled model, defining its input and output ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlr import DLRModel\n",
    "import numpy\n",
    "input_shape = {'data': [1, 3, 224, 224]} # A single RGB 224x224 image\n",
    "output_shape = [1, 1000]                 # The probability for each one of the 1,000 classes\n",
    "device = 'cpu'                           # Go, Raspberry Pi, go!\n",
    "\n",
    "model = DLRModel(model_path='compiled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we are going to now check single inference against our compiled model using same image we used in our inference against the original model above.  We will first load & resize the image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"data/cat.png\", 1)\n",
    "print(image.shape)\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "image = cv2.resize(image, (32, 32))\n",
    "\n",
    "input_data = {'Placeholder': numpy.asarray(image).astype(float).tolist()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check single a inference against our compiled model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.run(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again get mean value using python timeit module for measuring inference time on the compiled model. We will use this value for comparison against the original model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_compiled = %timeit -n25 -r25 -o model.run(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = float(str(time_compiled)[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o2 = float(str(time_original)[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see the results comparing our inference using a single image against our original model and our compiled model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Original Model: {} vs Compiled Model: {}ms ... {} x speedup!'.format(o2,o1,o2/o1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
